{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# installing dependencies\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 23:38:12.899365: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-20 23:38:12.901285: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-20 23:38:12.926819: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-20 23:38:12.926852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-20 23:38:12.927621: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-20 23:38:12.932137: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-20 23:38:12.932889: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 23:38:13.591754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_segment_name</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Violence_start</th>\n",
       "      <th>Violence_end</th>\n",
       "      <th>Violence_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry_011</td>\n",
       "      <td>117.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry_011</td>\n",
       "      <td>117.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry_011</td>\n",
       "      <td>117.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry_011</td>\n",
       "      <td>117.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry_011</td>\n",
       "      <td>117.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_segment_name  Duration  Violence_start  Violence_end  Violence_duration\n",
       "0         angry_011     117.0            21.0          38.0               17.0\n",
       "1         angry_011     117.0            40.0          55.0               15.0\n",
       "2         angry_011     117.0            60.0          79.0               19.0\n",
       "3         angry_011     117.0            85.0          95.0               10.0\n",
       "4         angry_011     117.0           101.0         110.0                9.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the excel file and load it into a Dataframe\n",
    "DIR_EXCEL = os.path.join('..', 'data', 'VSD.xlsx')\n",
    "df = pd.read_excel(DIR_EXCEL, sheet_name='read_dataset')\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3050.9139999999998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Violence_duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['angry_011.wav',\n",
       " 'angry_012.wav',\n",
       " 'angry_013.wav',\n",
       " 'angry_014.wav',\n",
       " 'angry_015.wav',\n",
       " 'angry_211.wav',\n",
       " 'noviolence_01.wav',\n",
       " 'noviolence_02.wav',\n",
       " 'noviolence_03.wav',\n",
       " 'noviolence_04.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all audio filenames into a list (discard redundant audios, example: angry_01.wav)\n",
    "DIR_DATA = os.path.join('..', 'data', 'audios_VSD', 'audios_VSD')\n",
    "redundant_audio_len = len('angry_01.wav')\n",
    "filenames = [filename for filename in os.listdir(DIR_DATA) if len(filename) != redundant_audio_len]\n",
    "print(len(filenames)) # how many audio files do we have (excluding redundant audios)\n",
    "filenames[:5] + filenames[len(filenames)-5:] # print first 5 and last 5 filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry_203.wav', 'angry_204.wav', 'angry_205.wav', 'angry_206.wav', 'angry_211.wav']\n",
      "['noviolence_01.wav', 'noviolence_02.wav', 'noviolence_03.wav', 'noviolence_04.wav']\n"
     ]
    }
   ],
   "source": [
    "# let's divide toxic audio filenames and non-toxic audio filenames\n",
    "toxic_filenames = filenames[:-4]\n",
    "nontoxic_filenames = filenames[-4:]\n",
    "print(toxic_filenames[-5:])\n",
    "print(nontoxic_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angry_011.wav'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXAMPLE_FILENAME = filenames[0]\n",
    "EXAMPLE_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to get wave data from an audio file\n",
    "SAMPLES_PER_SECOND = 16000\n",
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=SAMPLES_PER_SECOND)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 23:38:14.874960: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-02-20 23:38:14.931094: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1872000,), dtype=float32, numpy=\n",
       "array([-1.5588116e-06,  4.4376916e-06, -4.4316839e-06, ...,\n",
       "       -3.2952270e-01, -3.9674458e-01, -3.0953401e-01], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get wave from example audio file and plot it\n",
    "wave = load_wav_16k_mono(os.path.join(DIR_DATA, EXAMPLE_FILENAME))\n",
    "wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(wave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f93ac694f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f93ac6952d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "# get all waves from all audiofiles\n",
    "waves = []\n",
    "for filename in toxic_filenames:\n",
    "    waves.append((filename, load_wav_16k_mono(os.path.join(DIR_DATA, filename))))\n",
    "print(len(waves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3044 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's slice the waves and retrieve ONLY the toxic segments\n",
    "segments = []\n",
    "audio_length = 0 # sum all segments length in seconds\n",
    "for filename, wave in waves:\n",
    "    sub_df = df[df['File_segment_name'] == filename[:-4]]\n",
    "    for i in range(sub_df.shape[0]):\n",
    "        start = sub_df.iloc[i][2]\n",
    "        start_sample = int(start * SAMPLES_PER_SECOND) # calculate the start of the segment in sample index\n",
    "        size = sub_df.iloc[i][4]\n",
    "        size_sample = int(size * SAMPLES_PER_SECOND) # calculate the size of the segment in number of samples\n",
    "        if start_sample + size_sample >= len(wave): # make sure that the start + size of the segment don't go outside audio boundries\n",
    "            size_sample = len(wave) - start_sample\n",
    "        if size_sample < 1 * SAMPLES_PER_SECOND: # exclude audio segments shorter than 1 second (excluding 27 segments)\n",
    "            continue\n",
    "        audio_length += size_sample # keep adding the segment length in seconds\n",
    "        slice = tf.slice(wave, begin=[start_sample], size=[size_sample])\n",
    "        segments.append((filename[:-4] + \"_\" + str(i), slice))\n",
    "audio_length_secs = audio_length // SAMPLES_PER_SECOND\n",
    "print(audio_length_secs, \"seconds\")\n",
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(48704000,), dtype=float32, numpy=\n",
       "array([-0.00717086, -0.00667315, -0.00130043, ..., -0.02748326,\n",
       "       -0.04429958, -0.03331839], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that we have 3044 seconds of only toxic audio...\n",
    "# let's join all segments, and slice them again in 10 second segments\n",
    "# this will give us 304 equal length segments that we can use to train a model\n",
    "segments_joined = tf.concat([segment[1] for segment in segments], 0)\n",
    "# get rid of the last 4 seconds, just so we have exactly 3040 seconds\n",
    "segments_joined = segments_joined[:SAMPLES_PER_SECOND * audio_length_secs]\n",
    "segments_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([-0.00717086, -0.00667315, -0.00130043, ..., -0.01246491,\n",
       "        -0.02152932, -0.03510552], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([-0.00289301,  0.03021058,  0.06220048, ...,  0.01427979,\n",
       "         0.00470128, -0.01379599], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([-1.3426694e-02, -1.5097812e-02, -1.8019384e-02, ...,\n",
       "        -1.0372097e-02,  3.7835867e-05,  1.3889559e-02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([ 0.00511254, -0.01175897, -0.02543719, ...,  0.01161133,\n",
       "        -0.00840763, -0.0119929 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([ 0.00732741,  0.00285657, -0.00698765, ..., -0.06338346,\n",
       "        -0.1051461 , -0.12990886], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create the 10 second segments out of the 3040 sec of toxic audio only\n",
    "SECONDS_PER_SEGMENT = 10\n",
    "num_segments = audio_length_secs // SECONDS_PER_SEGMENT\n",
    "SAMPLES_PER_SEGMENT = SECONDS_PER_SEGMENT * SAMPLES_PER_SECOND\n",
    "new_segments = []\n",
    "for i in range(num_segments):\n",
    "    start_sample = i * SAMPLES_PER_SECOND\n",
    "    new_segment = tf.slice(segments_joined, begin=[start_sample], size=[SAMPLES_PER_SEGMENT])\n",
    "    new_segments.append(new_segment)\n",
    "print(len(new_segments))\n",
    "new_segments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have 304 TOXIC audio segments\n",
    "# let's create 304 NON-TOXIC audio segments\n",
    "# just so we have balanced data to train a model\n",
    "nontoxic_waves = []\n",
    "# due to the great length of non toxic audios we have to process them 1 by 1, outside a loop\n",
    "filename = nontoxic_filenames[0:1][0]\n",
    "nontoxic_waves.append((filename, load_wav_16k_mono(os.path.join(DIR_DATA, filename))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This audio contains too many zeroes. Let's skip it for now.\n",
    "# due to the great length of non toxic audios we have to process them 1 by 1, outside a loop\n",
    "# filename = nontoxic_filenames[1:2][0]\n",
    "# nontoxic_waves.append((filename, load_wav_16k_mono(os.path.join(DIR_DATA, filename))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This audio is TOO LARGE, don't run this block\n",
    "# due to the great length of non toxic audios we have to process them 1 by 1, outside a loop\n",
    "# filename = nontoxic_filenames[2:3][0]\n",
    "# nontoxic_waves.append((filename, load_wav_16k_mono(os.path.join(DIR_DATA, filename))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the great length of non toxic audios we have to process them 1 by 1, outside a loop\n",
    "filename = nontoxic_filenames[3:4][0]\n",
    "nontoxic_waves.append((filename, load_wav_16k_mono(os.path.join(DIR_DATA, filename))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('noviolence_01.wav',\n",
       "  <tf.Tensor: shape=(79023542,), dtype=float32, numpy=\n",
       "  array([ 0.0000000e+00, -1.5518568e-10,  5.7849368e-11, ...,\n",
       "          1.3298860e-03,  5.5263093e-04,  5.1844068e-04], dtype=float32)>),\n",
       " ('noviolence_04.wav',\n",
       "  <tf.Tensor: shape=(59695856,), dtype=float32, numpy=\n",
       "  array([ 0.        ,  0.        ,  0.        , ...,  0.00554482,\n",
       "         -0.02701107, -0.03128438], dtype=float32)>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontoxic_waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 42439714), (0, 16491501), (0, 29060746), (0, 13600358), (0, 23827472)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's randomnly create 304 segments from the loaded nontoxic audio files\n",
    "import random\n",
    "# let's define the segment starts and ensure that they don't overlap (we don't want redundant data for training)\n",
    "starts = []\n",
    "num_segments = 304\n",
    "for i in range(num_segments):\n",
    "    # first let's randomly select 1 out of the 3 nontoxic audio files\n",
    "    new_audio_index = random.randint(0, len(nontoxic_waves)-1)\n",
    "    current_size = len(starts)\n",
    "    while current_size == len(starts):\n",
    "        new_start = random.randint(0, len(nontoxic_waves[new_audio_index][1]))\n",
    "        passed_validation = True\n",
    "        for audio_index, start in starts:\n",
    "            if new_audio_index != audio_index:\n",
    "                continue\n",
    "            if new_start >= start - SAMPLES_PER_SEGMENT and new_start <= start + SAMPLES_PER_SEGMENT:\n",
    "                passed_validation = False\n",
    "                break\n",
    "            if new_start + SAMPLES_PER_SEGMENT >= len(nontoxic_waves[new_audio_index][1]):\n",
    "                passed_validation = False\n",
    "                break\n",
    "        if passed_validation:\n",
    "            starts.append((new_audio_index, new_start))\n",
    "print(len(starts))\n",
    "starts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLES_PER_SEGMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([ 0.03724594,  0.03804259,  0.04164317, ...,  0.00084975,\n",
       "        -0.00115096, -0.00121317], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([-0.01415091, -0.01351208, -0.08192375, ..., -0.00840883,\n",
       "         0.00607567, -0.00568069], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([-0.09857059, -0.09281269, -0.09375795, ..., -0.00931696,\n",
       "        -0.01029179, -0.0046925 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([-0.02128833, -0.02228308, -0.0225965 , ..., -0.04452484,\n",
       "        -0.03110448, -0.01466554], dtype=float32)>,\n",
       " <tf.Tensor: shape=(160000,), dtype=float32, numpy=\n",
       " array([ 1.0806185e-02,  1.6107699e-02,  1.3992631e-02, ...,\n",
       "        -1.1816708e-03, -2.6568978e-03,  4.2064465e-05], dtype=float32)>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that we have the randomly generated starts of the non toxic audio segments\n",
    "# let's actually go ahead and generate these segments based on the non overlapping starts\n",
    "nontoxic_segments = []\n",
    "for i, start in enumerate(starts):\n",
    "    nontoxic_wave = nontoxic_waves[start[0]][1] # get the corresponding nontoxic audio tensor\n",
    "    slice = tf.slice(nontoxic_wave, begin=[start[1]], size=[SAMPLES_PER_SEGMENT])\n",
    "    nontoxic_segments.append(slice) # (nontoxic_waves[start[0]][0][:-4] + \"_\" + str(i),\n",
    "print(len(nontoxic_segments))\n",
    "nontoxic_segments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "304\n"
     ]
    }
   ],
   "source": [
    "# Now we finally have 304 TOXIC AUDIO FILES of 10 SECOND LENGTH and 304 NON-TOXIC AUDIO FILES of 10 second length as well\n",
    "# They are both saved in the following variables:\n",
    "toxic_segments = new_segments\n",
    "print(len(toxic_segments)) # toxic segments\n",
    "print(len(nontoxic_segments)) # non-toxic segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Failed: tried to convert segments back into audios\n",
    "# file_contents = tf.io.read_file(os.path.join(DIR_DATA, toxic_filenames[0]))\n",
    "# # Decode wav (tensors by channels) \n",
    "# wav, sample_rate_ = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "# sample_rate_\n",
    "# tf.audio.encode_wav(wav, sample_rate=sample_rate_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's convert our audio segments into spectograms, as these will be used to train the model\n",
    "def convert_wav_into_spectrogram(wav, label):\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label\n",
    "\n",
    "# following function is discarded for now\n",
    "def convert_wavs_into_spectrograms(wavs):\n",
    "    # return [convert_wav_into_spectrogram(wav) for wav in wavs]\n",
    "    spectrograms = []\n",
    "    for i, wav in enumerate(wavs):\n",
    "        print(i, end=\", \")\n",
    "        spectrograms.append(convert_wav_into_spectrogram(wav))\n",
    "    return spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toxic_spectrograms = convert_wavs_into_spectrograms(toxic_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nontoxic_spectrograms = convert_wavs_into_spectrograms(nontoxic_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(toxic_spectrograms))\n",
    "print(len(nontoxic_spectrograms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now that we have the spectrograms, let's visualize a couple of them, 1 toxic and 1 non-toxic\n",
    "# TOXIC SPECTROGRAM\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(tf.transpose(toxic_spectrograms[32])[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON-TOXIC SPECTROGRAM\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(tf.transpose(nontoxic_spectrograms[32])[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(toxic_spectrograms[0].shape)\n",
    "display(nontoxic_spectrograms[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = tf.data.Dataset.from_tensor_slices(toxic_segments)\n",
    "neg = tf.data.Dataset.from_tensor_slices(nontoxic_segments)\n",
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "data = positives.concatenate(negatives)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02248843, -0.0230893 , -0.01703623, ...,  0.03062811,\n",
       "         0.04080442,  0.03917713], dtype=float32),\n",
       " 1.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()\n",
    "wav, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram, label = convert_wav_into_spectrogram(wav, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(convert_wav_into_spectrogram)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16) # creates 38 batches of 16 audio samples per batch = 608 audio samples\n",
    "data = data.prefetch(8) # to avoid CPU bottlenecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "27\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# let's calculate the number of batches for test and training\n",
    "import math\n",
    "print(len(data)) # 38 batches of 16 audio samples\n",
    "train_num_batches = math.ceil(len(data)*0.7)\n",
    "test_num_batches = math.floor(len(data)*0.3)\n",
    "print(train_num_batches) # train number of batches\n",
    "print(test_num_batches) # test number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_num_batches)\n",
    "test = data.skip(train_num_batches).take(test_num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4991, 257, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples, labels = train.as_numpy_iterator().next()\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(4991, 257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 4989, 255, 16)     160       \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 4987, 253, 16)     2320      \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 20187376)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2480 (9.69 KB)\n",
      "Trainable params: 2480 (9.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Test One Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples, labels = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Load Tensorflow Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Build Sequential Model, Compile and View Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(4991, 257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Fit Model, View Loss and KPI Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=4, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Make a Prediction on a Single Clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Get One Batch and Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Convert Logits to Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 9. Build Forest Parsing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Load up MP3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mp3_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    res = tfio.audio.AudioIOTensor(filename)\n",
    "    # Convert to tensor and combine channels \n",
    "    tensor = res.to_tensor()\n",
    "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 \n",
    "    # Extract sample rate and cast\n",
    "    sample_rate = res.rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Resample to 16 kHz\n",
    "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav = load_mp3_16k_mono(mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, index = audio_slices.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Build Function to Convert Clips into Windowed Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mp3(sample, index):\n",
    "    sample = sample[0]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, sample],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Convert Longer Clips into Windows and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
    "audio_slices = audio_slices.map(preprocess_mp3)\n",
    "audio_slices = audio_slices.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(audio_slices)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4 Group Consecutive Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [key for key, group in groupby(yhat)]\n",
    "calls = tf.math.reduce_sum(yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Loop over all recordings and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
    "    FILEPATH = os.path.join('data','Forest Recordings', file)\n",
    "    \n",
    "    wav = load_mp3_16k_mono(FILEPATH)\n",
    "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "    audio_slices = audio_slices.map(preprocess_mp3)\n",
    "    audio_slices = audio_slices.batch(64)\n",
    "    \n",
    "    yhat = model.predict(audio_slices)\n",
    "    \n",
    "    results[file] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Convert Predictions into Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_preds = {}\n",
    "for file, logits in results.items():\n",
    "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Group Consecutive Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "postprocessed = {}\n",
    "for file, scores in class_preds.items():\n",
    "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
    "postprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('results.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(['recording', 'capuchin_calls'])\n",
    "    for key, value in postprocessed.items():\n",
    "        writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
